import asyncio
import json
import os
import uuid
import prefect
from prefect import task, Flow, Client
from prefect.storage import Docker
from prefect.run_configs import KubernetesRun
from malwaretl_stoq_transformer import transformer


DEBUG = False

if DEBUG is False:
    BASE_DIR = "/malware"
    OUTPUT_DIR = "/results"
else:
    BASE_DIR = "/Volumes/raw_malware"
    OUTPUT_DIR = "/tmp/"

SOURCE_DIRECTORIES = {
    # "github-android-malware": ["github-android-malware/android-malware"],
    "malshare": ["malshare/2021", "malshare/2022"],
    "malwerk": ["malwerk/"],
    "mbazaar": ["mbazaar"],
    # "theZoo": ["theZoo/theZoo/malware"],
    "urlhaus": ["urlhaus/2021", "urlhaus/2022"],
    "vxug": ["vxug/APT Collection",
             "vxug/Argus Collection",
             "vxug/Bazaar Collection",
             "vxug/Virusshare Collection"],
    "vxvault": ["vxvault"]
}


async def scan(stoq, archive_path, output_dir):
    logger = prefect.context.get("logger")

    with open(archive_path, "rb") as filehandle:
        results = await stoq.scan(content=filehandle.read())
        async for result in stoq.reconstruct_all_subresponses(results):
            # not a super-fan of this, but I need to get the results to json quickly. That seems to involve
            # letting stoq do it's to-json-string magic, then pulling it back:
            string_result = str(result)
            decoded = json.loads(string_result)
            for entry in decoded.get("results", []):

                try:
                    sha256 = entry['payload_meta']['extra_data']['sha256']
                except KeyError:
                    try:
                        sha256 = entry['workers']['hash']['sha256']
                    except KeyError:
                        logger.info(f"failed to find hash in {entry}")
                        continue
                output_path = os.path.join(output_dir, sha256 + ".json")
                if not os.path.exists(output_path):
                    with open(output_path, "w") as outfile:
                        json.dump(entry, outfile)



@task
def prefect_task(job_id):
    logger = prefect.context.get("logger")
    logger.info(f"beginning task with job id {job_id}")

    analyze(job_id)
    logger.info(f"finished task with job id {job_id}")


def analyze(job_id):
    # for each collector, walk over its archive folder, hand each found file to stoq, but don't write results to
    # elasticsearch, write them to a flat .json file for each malware sample
    loop = asyncio.new_event_loop()
    stoq = None
    logger = prefect.context.get("logger")
    for source in SOURCE_DIRECTORIES:
        logger.info(f"starting {source}")
        output_dir = os.path.join(OUTPUT_DIR, "feature_extraction", job_id, source)
        if not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        for directory in SOURCE_DIRECTORIES[source]:
            full_path = os.path.join(BASE_DIR, directory)
            logger.info(f"looking at {full_path}")
            for root, dirs, files in os.walk(full_path):
                if DEBUG is False:
                    input_mode = transformer.InputMode.manual
                    output_mode = transformer.OutputMode.silent
                    stoq = transformer.make_stoq("",input_mode=input_mode, output_mode=output_mode)
                    # suppress the stoq worker logs. I wish the "failed to scan" logs weren't "error" level
                    stoq.log.disabled = True
                for archive in files:
                    archive_path = os.path.join(root, archive)
                    logger.info(f"looking at {archive}")
                    if DEBUG is False:
                        loop.run_until_complete(scan(stoq, archive_path, output_dir))
                    else:
                        logger.info(f"evaluating {archive_path}")


def main():
    job_id = str(uuid.uuid4())
    with Flow("malwareETL feature extractor",
              storage=Docker(registry_url="prefect-ui.g-clef.net:5000",
                             base_image="gclef/stoq-transformer:latest-prefect"
                             ),
              run_config=KubernetesRun(memory_request="2Gi", memory_limit="2Gi")) as flow:
        prefect_task(job_id)

    client = Client(api_server="http://prefect-ui.g-clef.net:4200/graphql")
    client.register(flow=flow, project_name="malware-feature-extraction")


if __name__ == "__main__":
    if DEBUG is False:
        main()
    else:
        analyze("testing")
